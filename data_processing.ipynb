{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61659959",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59209fe5",
   "metadata": {},
   "source": [
    "The images that are being processed depict people each showing a letter from the ASL alphabet. The images used in this project are not published, the resulting datapoints from the images are published (data_unprocessed.pickle). If somebody wants to complete the entire project, the data_collection file can be used to create picture to process them in this file.   \n",
    "\n",
    "The library Mediapipe provides methods to extract landmarks from one or multiple hands. The landmarks are:\n",
    "\n",
    "![alt text](hand-landmarks.png \"Title\")\n",
    "\n",
    "From each picture, the landmarks of the hand signing a letter from the ASL alphabet are extracted. The label indicating which letter is being signed is extracted from the folder name. All pictures showing a person signing the letter \"A\" are saved in the folder 0, all pictures showing a person signing the letter \"B\" are saved in the folder 1, and so on and forth. A data file is created where 63 landmarks per hand are stored, for each dimension in the 3D word (x,y,z-axis) 21 landmarks per hand are stored, which corresponds to 63 landmarks per hand. For each hand, a label is saved, indicating which letter is being signed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f548fe37",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7c810d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-03 10:53:37.338945: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e447024",
   "metadata": {},
   "source": [
    "## Extract landmarks from images and save them in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fa4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True) #input is static img\n",
    "\n",
    "DATA_DIR = './data_collection'\n",
    "landmarks = []\n",
    "labels = []\n",
    "\n",
    "for dir_name in os.listdir(DATA_DIR):\n",
    "    if dir_name != \".DS_Store\": # exclude metadata file\n",
    "        dir_path = os.path.join(DATA_DIR, dir_name)\n",
    "        if os.path.isdir(dir_path): # check if it is a directory\n",
    "            for img_name in os.listdir(dir_path):\n",
    "                img_path = os.path.join(dir_path, img_name)\n",
    "                if os.path.isfile(img_path): # check if it is a file\n",
    "                    img_rgb = cv2.imread(img_path)\n",
    "                    \n",
    "                    try:\n",
    "                        # extract hand landmark; returns object that contains a list of 21 3D hand landmarks \n",
    "                        results = hands.process(img_rgb)\n",
    "                        coordinates = []\n",
    "                        if results.multi_hand_landmarks:\n",
    "                            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                                for i in range(len(hand_landmarks.landmark)):\n",
    "                                    x = hand_landmarks.landmark[i].x\n",
    "                                    y = hand_landmarks.landmark[i].y\n",
    "                                    z = hand_landmarks.landmark[i].z\n",
    "                                    coordinates.append(x)\n",
    "                                    coordinates.append(y)\n",
    "                                    coordinates.append(z)\n",
    "                            if len(coordinates) == 63: #only append data that has the right amount of landmarkers (3x21)\n",
    "                                landmarks.append(coordinates) #landmarks, x,y,z-coorindates, for each coordinate 21 points\n",
    "                                labels.append(dir_name) #label between 0 and 25, correspondening to the alphabet\n",
    "                    \n",
    "                    except AttributeError:\n",
    "                        print(\"Attribute Error - Skip Image\")\n",
    "\n",
    "    f = open('data_unprocessed.pickle', 'wb') #data\n",
    "    pickle.dump({'landmarks': landmarks, 'labels': labels}, f) #save data\n",
    "    f.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845f5c4c",
   "metadata": {},
   "source": [
    "## Transform pickle file into structured csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f1e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('data_unprocessed.pickle', 'rb'))\n",
    "data = np.asarray(data_dict['landmarks']) # all landmarks\n",
    "labels = np.asarray(data_dict['labels']) # label \n",
    "\n",
    "#Transform the data into shape (amount of pics, 64) -> 63 landmarks per pic and 1 label\n",
    "data_transformed = pd.DataFrame()\n",
    "for x in range(0,len(data)):\n",
    "    data_transformed[x] = data[x]\n",
    "data_transformed = data_transformed.T\n",
    "data_transformed[\"label\"] = labels\n",
    "data_transformed.shape\n",
    "data_transformed.to_csv('data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
